{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import random\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [],
   "source": [
    "patterns = [np.matrix([[x], [y]]) for x, y in [(2,4), (1,0.5), (0.5,1.5), (0,0.5)]]\n",
    "labels = [1, 1, -1, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [],
   "source": [
    "def get_shuffled(labels, patterns):\n",
    "    zipped = list(zip(labels, patterns))\n",
    "    random.shuffle(zipped)\n",
    "    labels_shuf, patterns_shuf = list(zip(*zipped))\n",
    "    return labels_shuf, patterns_shuf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) How many iterations are required by the pattern-based perceptron learning rule in order to seperate classes A and B correctly if the weight vector w is initialized as (0, 1, −1) and step size η is set to 0.1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [],
   "source": [
    "from scipy.special import expit as sigmoid\n",
    "\n",
    "class Perceptron:\n",
    "    def __init__(self, initial_weights):\n",
    "        self._initial_weights = initial_weights\n",
    "        self.weights = initial_weights[:]\n",
    "        \n",
    "    def _add_bias(self, data):\n",
    "        return np.vstack([[1], data])\n",
    "    \n",
    "    def reset(self):\n",
    "        self.weights = self._initial_weights[:]\n",
    "        \n",
    "    def predict(self, data):\n",
    "        if len(self.weights) - len(data) == 1:\n",
    "            data = self._add_bias(data)\n",
    "        return np.sign(sum(w*data[j] for j, w in enumerate(self.weights)))\n",
    "    \n",
    "    def fit(self, data, classes, learn_rate, max_iterations):\n",
    "        raise NotImplemented()\n",
    "    \n",
    "    \n",
    "class PatternPerceptron(Perceptron):\n",
    "    def fit(self, data, classes, learn_rate=0.1, max_iterations=100):\n",
    "        # Add bias to data\n",
    "        data = [np.vstack([[1], d]) for d in data]\n",
    "        def has_converged():\n",
    "            return all(self.predict(x) == y\n",
    "                                    for x, y in zip(data, classes))\n",
    "        iterations = 0\n",
    "        while iterations < max_iterations and not has_converged():\n",
    "            iterations += 1\n",
    "            # Error is here, we must not take *all* data into account, but merely a single one\n",
    "            # that we pick sequentially\n",
    "            # => Sample-based learning!\n",
    "            currently_misclassified = [(x, y) for x, y in zip(data, classes)\n",
    "                                       if self.predict(x) != y]\n",
    "            for j in range(len(self.weights)):\n",
    "                increase = learn_rate * sum(y*x[j] for x, y in currently_misclassified)\n",
    "                self.weights[j] += increase\n",
    "        if not has_converged():\n",
    "            raise Exception(\"Did not converge after {} iterations\"\n",
    "                            .format(iterations))\n",
    "        return iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 1 iterations are required.\n"
     ]
    }
   ],
   "source": [
    "p = PatternPerceptron(initial_weights=[0, 1, -1])\n",
    "print(\"Answer: {} iterations are required.\".format(\n",
    "    p.fit(patterns, labels, learn_rate=0.1, max_iterations=2000)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CORRECT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) How many iterations are required if η = 0.25?    Is the order of the considered patterns relevant? If so, give an example, otherwise, prove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 2 iterations are required with η = 0.25.\n",
      "Answer: With the patterns in shuffled order, we needed {2} iterations, so the order does not seem to be relevant.\n"
     ]
    }
   ],
   "source": [
    "p.reset()\n",
    "print(\"Answer: {} iterations are required with η = 0.25.\".format(\n",
    "    p.fit(patterns, labels, learn_rate=0.25, max_iterations=100)))\n",
    "\n",
    "randomized_iters = []\n",
    "for _ in range(100):\n",
    "    p.reset()\n",
    "    labels_shuf, patterns_shuf = get_shuffled(labels, patterns)\n",
    "    randomized_iters.append(\n",
    "        p.fit(patterns_shuf, labels_shuf, learn_rate=0.25,\n",
    "              max_iterations=100))\n",
    "print(\"Answer: With the patterns in shuffled order, we needed {} iterations, so \"\n",
    "      \"the order does not seem to be relevant.\".format(set(randomized_iters)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOT CORRECT -> Should be 6 iterations\n",
    "NOT CORRECT -> Does matter\n",
    "??? How to prove that this must be the case ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) After how many iterations does the gradient-based learning rule terminate for both η? In this case: Is the order of the considered patterns relevant?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [],
   "source": [
    "class GradientPerceptron(Perceptron):\n",
    "    def fit(self, data, classes, learn_rate=0.1, max_iterations=100):\n",
    "        # Add bias to data\n",
    "        data = [np.vstack([[1], d]) for d in data]\n",
    "        has_converged = lambda: all(self.predict(x) == y\n",
    "                                    for x, y in zip(data, classes))\n",
    "        iterations = 0\n",
    "        while iterations < max_iterations and not has_converged():\n",
    "            iterations += 1\n",
    "            # ERROR: According to the solution, we should go over *all* misclassified patterns??\n",
    "            i = np.random.randint(len(data))\n",
    "            # We only want to select misclassified patterns\n",
    "            if classes[i] == self.predict(data[i]):\n",
    "                continue\n",
    "            for j in range(len(self.weights)):\n",
    "                increase = learn_rate * classes[i] * data[i][j]\n",
    "                self.weights[j] += increase\n",
    "        if not has_converged():\n",
    "            raise Exception(\"Did not converge after {} iterations\"\n",
    "                            .format(iterations))\n",
    "        return iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [],
   "source": [
    "gp = GradientPerceptron(initial_weights=[0, 1, -1])\n",
    "for rate in (0.1, 0.25):\n",
    "    gp.reset()\n",
    "    gp.fit(patterns, labels, learn_rate=rate, max_iterations=100)\n",
    "    print(\"Answer: With a rate of {}, gradient-based learning terminates.\".format(rate))\n",
    "\n",
    "for rate in (0.1, 0.25):\n",
    "    for _ in range(100):\n",
    "        gp.reset()\n",
    "        labels_shuf, patterns_shuf = get_shuffled(labels, patterns)\n",
    "        gp.fit(patterns_shuf, labels_shuf, learn_rate=0.1,\n",
    "              max_iterations=100)\n",
    "    print(\"With a rate of {} and shuffled data and labels it seems to terminate as well.\".format(rate))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
