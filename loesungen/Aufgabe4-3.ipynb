{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we will extend the previous network to a convolutional architecture with max-pooling. To warm up, first answer the following questions, assuming that we have an input image of size (28,28):\n",
    "* What are the output dimensions when filtering this image using a convolution in \"valid\" mode with a filter size of (5,5)?\n",
    "\n",
    "Answer: (24,24)\n",
    "* When this output is filtered using max-pooling with a filter size of (2,2), what is the dimension of the output?\n",
    "\n",
    "Answer:(12,12)\n",
    "* What would be the output when convolving the (28,28) pixel image with a filter of size (5,5) in \"full\" and \"same\" modes?\n",
    "\n",
    "Answer: (32,32) and (28,28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following we will build a Convolutional Neural Network with these building blocks and Theano. Note that the training can take rather long without GPU support, if necessary train on a small dataset for some preliminary tests and later switch to a larger training set for final results. The theano implementation of this exercise is not mandatory and not relevant for your final exams -- understanding convolutions and max-pooling, however, is relevant.\n",
    "\n",
    "Import the dataset, do not flatten the images. You should however flatten the labels. Reshape the images to get a tensor of shape ${\\tt (batchsize,1,28,28)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os, struct\n",
    "from array import array as pyarray\n",
    "from numpy import append, array, int8, uint8, zeros\n",
    "\n",
    "mnist_path=\"/path/to/mnist\"\n",
    "\n",
    "def load_mnist(dataset=\"training\", digits=np.arange(10), path=\".\"):\n",
    "    \"\"\"\n",
    "    Loads MNIST files into 3D numpy arrays\n",
    "\n",
    "    Adapted from: http://abel.ee.ucla.edu/cvxopt/_downloads/mnist.py\n",
    "    \"\"\"\n",
    "\n",
    "    if dataset == \"training\":\n",
    "        fname_img = os.path.join(path, 'train-images-idx3-ubyte')\n",
    "        fname_lbl = os.path.join(path, 'train-labels-idx1-ubyte')\n",
    "    elif dataset == \"testing\":\n",
    "        fname_img = os.path.join(path, 't10k-images-idx3-ubyte')\n",
    "        fname_lbl = os.path.join(path, 't10k-labels-idx1-ubyte')\n",
    "    else:\n",
    "        raise ValueError(\"dataset must be 'testing' or 'training'\")\n",
    "\n",
    "    flbl = open(fname_lbl, 'rb')\n",
    "    magic_nr, size = struct.unpack(\">II\", flbl.read(8))\n",
    "    lbl = pyarray(\"b\", flbl.read())\n",
    "    flbl.close()\n",
    "\n",
    "    fimg = open(fname_img, 'rb')\n",
    "    magic_nr, size, rows, cols = struct.unpack(\">IIII\", fimg.read(16))\n",
    "    img = pyarray(\"B\", fimg.read())\n",
    "    fimg.close()\n",
    "\n",
    "    ind = [ k for k in range(size) if lbl[k] in digits ]\n",
    "    N = len(ind)\n",
    "\n",
    "    images = zeros((N, rows, cols), dtype=uint8)\n",
    "    labels = zeros((N, 1), dtype=int8)\n",
    "    for i in range(len(ind)):\n",
    "        images[i] = array(img[ ind[i]*rows*cols : (ind[i]+1)*rows*cols ]).reshape((rows, cols))\n",
    "        labels[i] = lbl[ind[i]]\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1, 28, 28)\n",
      "(60000, 1, 28, 28)\n",
      "(60000,)\n",
      "(10000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: Tesla M2090\n"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "#Load the images for training and testing\n",
    "images, label = load_mnist(dataset=\"training\" , digits=np.arange(10), path=mnist_path)\n",
    "test_images, test_label = load_mnist(dataset=\"testing\" , digits=np.arange(10), path=mnist_path)\n",
    "#Flatten the images to get a vectorial representation\n",
    "images = images.astype(theano.config.floatX).reshape((images.shape[0],1,images.shape[1],images.shape[2]))\n",
    "test_images = test_images.astype(theano.config.floatX).reshape((test_images.shape[0],1,test_images.shape[1],test_images.shape[2]))\n",
    "#get the maximum for normalization and normalize to values in range [0,1]\n",
    "maxval = np.max(images)\n",
    "images = (images * (1.0/maxval)).astype(theano.config.floatX)\n",
    "test_images = (test_images * (1.0/maxval))\n",
    "#flatten the labels to get a vectorial representation\n",
    "label = label.flatten()\n",
    "test_label = test_label.flatten()\n",
    "print test_images.shape\n",
    "print images.shape\n",
    "print label.shape\n",
    "print test_label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the previously transformed training data, we want to define a Convolutional Neural Network for classification. Construct the following network:\n",
    "* Input $x$: (28,28)-dimensional\n",
    "* First layer: Convolutional layer with\n",
    "    * One Input channel (black/white image)\n",
    "    * Weights of the convolutional filter are initialized with a uniform distribution to [-0.06,0.06]\n",
    "    * 3 output channels (These output channels are called **feature maps**\n",
    "    * Filter size of 5x5\n",
    "    * Question: What are the output dimensions of this layer?\n",
    "* Second layer: Max-pooling layer with\n",
    "    * Filter size of 2x2\n",
    "    * Sigmoidal activation function and biases initialized to zero\n",
    "    * Flatten the outputs as the next layers will be equivalent to the previously defined MLP. You can use ${\\tt T.flatten(2)}$. The remainder of the network is mostly equivalent to the MLP.\n",
    "    * Question: What are the output dimensions of this layer?\n",
    "* Third layer: \n",
    "    * You have calculated the number of inputs by your own\n",
    "    * 100 hidden neurons output\n",
    "    * Weights of the convolutional filter are initialized with a uniform distribution to [-0.01,0.01]\n",
    "    * Sigmoidal activation function and biases initialized to zero\n",
    "* Fourth (classification) layer:\n",
    "    * 100 inputs\n",
    "    * 10 outputs\n",
    "    * Softmax activation function\n",
    "* Use a batch size of 100 and a learning rate of 2\n",
    "* Train 10 epochs. An epoch corresponds to a training interval where each training image is considered once.\n",
    "* Optimize with negative log-likelihood as a cost function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "import theano.tensor as T\n",
    "import numpy as np\n",
    "\n",
    "learning_rate = T.scalar('lr')\n",
    "index = T.lscalar('index')\n",
    "batch_size = 100\n",
    "train_set_x = theano.shared(value=images, name='train_set_x')\n",
    "train_set_y = T.cast(theano.shared(value=label, name='train_set_y'), 'int32')\n",
    "visible_size= (images.shape[2],images.shape[3])\n",
    "hidden_units=100\n",
    "output_units=10\n",
    "rng = numpy.random.RandomState(1242)\n",
    "epochs = 10\n",
    "n_train_batches = images.shape[0]/batch_size\n",
    "learn_rate = 2\n",
    "\n",
    "########################################\n",
    "##########INPUTS AND WEIGHTS############\n",
    "########################################\n",
    "x = T.tensor4('x')\n",
    "#output\n",
    "y = T.ivector('y')\n",
    "#input weights for the weight matrices are rather important; if they are not set correctly, results might get stuck in local minima\n",
    "W0 = theano.shared(value=numpy.asarray(rng.uniform(low=-0.035,high=0.035,size=(3,1,5,5)),dtype=theano.config.floatX), name='W0')\n",
    "b0 = theano.shared(value=numpy.zeros((3,12,12),dtype=theano.config.floatX), name='b0')\n",
    "#weights first layer\n",
    "W1 = theano.shared(value=numpy.asarray(rng.uniform(low=-0.01,high=0.01,size=(12*12*3,hidden_units)),dtype=theano.config.floatX), name='W1')\n",
    "#bias first layer\n",
    "b1 = theano.shared(value=numpy.zeros((hidden_units,),dtype=theano.config.floatX), name='b1')\n",
    "#weights second layer\n",
    "W2 = theano.shared(value=numpy.asarray(rng.uniform(low=-0.05,high=0.05,size=(hidden_units,output_units)),dtype=theano.config.floatX), name='W2')\n",
    "#bias second layer\n",
    "b2 = theano.shared(value=numpy.zeros((output_units,),dtype=theano.config.floatX), name='b2')\n",
    "\n",
    "########################################\n",
    "##############  NETWORK  ###############\n",
    "########################################\n",
    "conv1Out = T.nnet.conv.conv2d(x, W0, filter_shape=(3,1,5,5), border_mode='valid')\n",
    "maxPool1Out= T.signal.downsample.max_pool_2d(conv1Out, (2,2))\n",
    "activation1Out = T.nnet.sigmoid(maxPool1Out+b0)\n",
    "flattenOut = activation1Out.flatten(2)\n",
    "denselyConnected1Out = T.nnet.sigmoid(T.dot(flattenOut, W1)+b1)\n",
    "denselyConnected2Out = T.nnet.softmax(T.dot(denselyConnected1Out, W2)+b2)\n",
    "loss = -T.mean(T.log(denselyConnected2Out)[T.arange(y.shape[0]), y])\n",
    "\n",
    "prediction = T.argmax(denselyConnected2Out)\n",
    "\n",
    "########################################\n",
    "#######  GRADIENT AND UPDATES  #########\n",
    "########################################\n",
    "params = [W0,b0,W1,b1,W2,b2]\n",
    "gradient = T.grad(loss, params)\n",
    "updates = []\n",
    "for p, g in zip(params, gradient):\n",
    "   updates.append((p, p - learning_rate * g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = theano.function([index, learning_rate], loss, updates=updates,\n",
    "     givens = {x: train_set_x[(index * batch_size): ((index + 1) * batch_size)],\n",
    "               y: train_set_y[(index * batch_size): ((index + 1) * batch_size)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refinement epoch 0, cost  1.22253\n",
      "Refinement epoch 1, cost  0.232628\n",
      "Refinement epoch 2, cost  0.134234\n",
      "Refinement epoch 3, cost  0.096562\n",
      "Refinement epoch 4, cost  0.0746032\n",
      "Refinement epoch 5, cost  0.0611119\n",
      "Refinement epoch 6, cost  0.051688\n",
      "Refinement epoch 7, cost  0.0446962\n",
      "Refinement epoch 8, cost  0.0392554\n",
      "Refinement epoch 9, cost  0.0347863\n"
     ]
    }
   ],
   "source": [
    "for epoch in xrange(epochs):\n",
    "    # go through training set\n",
    "    c = []\n",
    "    for batch_index in xrange(n_train_batches):\n",
    "        c.append(train(batch_index, learn_rate))\n",
    "    print 'Refinement epoch %d, cost ' % epoch, numpy.mean(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The actual output class of the network can be easily derived by taking the ${\\tt argmax}_i y_i$. Evaluate your classifier on the test set and calculate your error rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 5, 5, 1)\n",
      "6\n",
      "6\n",
      "(18, 18, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPwAAAD7CAYAAABOrvnfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faf43002510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weights = W0.get_value()\n",
    "\n",
    "#weights = weights.swapaxes(0,1)\n",
    "weights = weights.swapaxes(1,3)\n",
    "weights = weights.swapaxes(1,2)\n",
    "print weights.shape\n",
    "\n",
    "def getImageMat(weights):\n",
    "    cols = 3\n",
    "    rows = 3\n",
    "    xwidth = weights.shape[1]+1\n",
    "    ywidth = weights.shape[2]+1\n",
    "    print xwidth\n",
    "    print ywidth\n",
    "    channels = 3\n",
    "    vis = numpy.zeros((rows*xwidth,cols*ywidth,channels),dtype=numpy.float32)\n",
    "    print vis.shape\n",
    "    for i in range(0,weights.shape[0]):\n",
    "        startx = ((i%rows)*xwidth)\n",
    "        endx = startx + weights.shape[1]\n",
    "        starty = (i/rows*ywidth)\n",
    "        endy = starty+weights.shape[2]\n",
    "        minval = (np.min(weights[i,:,:]))\n",
    "        maxval = (np.max(weights[i,:,:]))\n",
    "        vis[startx:endx, starty:endy, :] = weights[i,:,:]#((weights[i,:,:])-minval)/(maxval-minval) ANDERS ALS SONST!!!!s\n",
    "    return vis\n",
    "\n",
    "imgMat = getImageMat(weights)[:,:]\n",
    "minV = (np.min(imgMat[:,:]))\n",
    "maxV = (np.max(imgMat[:,:]))\n",
    "plt.imshow(((imgMat[:,:])-minV)/(maxV-minV),interpolation='none',cmap=\"seismic\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
