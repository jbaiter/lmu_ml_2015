{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Sheet 6\n",
    "\n",
    "## Exercise 6-1: Maximum Likelihood Estimator\n",
    "\n",
    "Suppose when soccer players train penalty kicks, each training session ends after their first miss, since they are demotivated. Let the probability of a miss be $p \\in [0,1]$. Then, the probability for exactly $x_i$ hits ($i \\in {1, . . . , N }$) before the first miss can be modeled using the geometric distribution:\n",
    "\n",
    "$$P(x_i) = p \\cdot (1 - p)^{x_i}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "breakpoint": false
    }
   },
   "source": [
    "### (a)\n",
    "\n",
    "Following a frequentist approach, determine the maximum likelihood estimator $p^{ML}$ for an i.i.d. (independent identically distributed) population of $N$ soccer players, which hit $x_i \\in {0, 1, . . . , \\infty}$ times before their first miss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "breakpoint": false
    }
   },
   "source": [
    "**Solution**\n",
    "\n",
    "$N$ = number of sessions<br>\n",
    "$p$ = probability of a miss<br>\n",
    "\n",
    "$L(p) = \\prod_{i=1}^N P(x_i) = \\prod_{i=1}^N p \\cdot (1 - p)^{x_i}$\n",
    "$l(p) = \\sum_{i=1}^N \\log P(x_i) = \\sum_{i=1}^N \\log (p \\cdot (1 - p)^{x_i}) = \\sum_{i=1}^N \\log(p) + \\sum_{i=1}^N \\log (1 - p)^{x_i} = N \\cdot \\log p + \\sum_{i=1}^N x_i \\cdot \\log(1 - p) = N \\cdot \\log p + log(1 - p) \\cdot \\sum_{i=1}^N x_i$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\int l}{\\int p} & = N \\cdot \\frac{1}{p} + \\frac{1}{1 -p} \\cdot (-1) \\cdot \\sum_{i=1}^N x_i \\\\\n",
    "                      & = \\frac{N}{p} - \\frac{1}{1 -p} \\cdot \\sum_{i=1}^Nx_i \\neq 0\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{N}{p} & = \\frac{1}{1-p} \\cdot \\sum_{i=1}^N x_i \\\\\n",
    "\\frac{1-p}{p} & = \\frac{1}{N} \\cdot \\sum_{i=1}^N x_i \\\\\n",
    "\\frac{1}{p} - 1 & = \\frac{1}{N} \\cdot \\sum_{i=1}^N x_i \\\\\n",
    "\\frac{1}{p} & = \\frac{1}{N} \\cdot \\sum_{i=1}^N x_i + 1 \\\\\n",
    "p^{ML} & = \\frac{1}{\\frac{1}{N} \\cdot \\sum_{i=1}^N x_i + 1}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "breakpoint": false
    }
   },
   "source": [
    "### (b)\n",
    "\n",
    "Consider the following dataset $X = [7, 2]$ for $N = 2$ training sessions. Compute the probability of a miss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "breakpoint": false
    }
   },
   "source": [
    "**Solution**\n",
    "\n",
    "$$\n",
    "\\frac{numSession}{numAttempts} = \\frac{N}{N + \\sum_{i=1}^N x_i} = \\frac{2}{2 + (7 + 2)} = \\frac{2}{11}\n",
    "$$\n",
    "\n",
    "Miss ($N$) + Hits ($\\sum_{i=1}^N x_i$) = Number of attempts\n",
    "\n",
    "Alternative:\n",
    "\n",
    "$$p^{ML} = \\frac{1}{\\frac{1}{2} \\cdot (7 + 2) + 1} = \\frac{1}{4.5 + 1} = \\frac{1}{5.5} = \\frac{2}{11}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "breakpoint": false
    }
   },
   "source": [
    "## Exercise 6-2: Frequentist versus Bayesian Statistics\n",
    "\n",
    "Consider this – rather pathological – example to illustrate the difference between frequentist and bayesian statistics: Alice and Bob play a game in which the first person to get 6 points wins. The points are scored in the following way: A referee is standing at a pool table Alice and Bob cannot see. Before the game begins, the referee rolls a ball onto the table coming to rest at a random position. Each point scored is decided by the referee rolling another ball. If the ball comes to rest left of (the middle of) the initial ball, Alice scores, if it comes to rest right, Bob scores. The players know nothing but who scored a point. If the portion left of the initial ball is denoted as $p$, it is obvious that the probability of Alice scoring a point is $p$.\n",
    "\n",
    "Now, consider the following situation within the game: Alice has 5 points, Bob has 3. Let us investigate the probability of Bob winning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)\n",
    "Assume that the initial ball came to rest such that $p = \\frac{2}{3}$. What is the probability that Bob wins?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "breakpoint": false
    }
   },
   "source": [
    "**Solution**\n",
    "\n",
    "<img src=\"img/img-6_2.jpg\" width=\"400\">\n",
    "\n",
    "$E_b = Bob wins$\n",
    "\n",
    "$P(E_b) = (1 - p)^3 = (1 - \\frac{2}{3})^3 = (\\frac{1}{3})^3 = \\frac{1}{27}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###(b)\n",
    "Unfortunately, we do not know $p$ – we only have some data we can try to estimate it from. Follow a *frequentist approach*: compute the maximum likelihood estimator for $p$ and the probability of Bob winning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "breakpoint": false
    }
   },
   "source": [
    "**Solution**\n",
    "$L(p) = \\prod_{i=1}^N P_p(x_i)$\n",
    "\n",
    "$P_p = 1 - p$ if $x_i = $ Bob makes a point\n",
    "\n",
    "$P_p = p$ if $x_i = $ Alice makes a point\n",
    "\n",
    "$l(p) = \\sum_{i=1}^N \\log P_p (x_i) = 3 \\cdot \\log(1 - p) + 5 \\cdot \\log p$\n",
    "\n",
    "$\n",
    "\\frac{\\partial l}{\\partial p} = 3 \\cdot \\frac{1}{1-p} \\cdot (-1) + 5 \\cdot \\frac{1}{p} = \\frac{5}{p} - \\frac{3}{1-p} \\\\\n",
    "\\frac{5}{p} = \\frac{3}{1-p} \\\\\n",
    "\\frac{1-p}{p} = \\frac{3}{5} \\\\\n",
    "\\frac{1}{p} = \\frac{3}{5} + 1 \\\\\n",
    "p^{ML} = \\frac{5}{8}\n",
    "$\n",
    "\n",
    "$P(E_b) = (1 - \\frac{5}{8})^3 = \\frac{27}{512} \\approx 0.053$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "breakpoint": false
    }
   },
   "source": [
    "###(c)\n",
    "Now, let us follow a bayesian approach: We know that $p$ is only dependent on the position of the initial ball which is uniformly distributed on the table, i.e., $unif[0,1]$. Note that we compute the expected probability of Bob winning, as $p$ itself is now drawn from a distribution. *Hint:* You will need the beta\n",
    "function:\n",
    "\n",
    "$$B(x, y) = \\int^1_0 t^{x-1} (1 - t)^{y-1}dt = \\frac{(x - 1)!(y - 1)!}{(x + y - 1)!}$$\n",
    "\n",
    "Optionally, you may implement the experiment and empirically compute the solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "breakpoint": false
    }
   },
   "source": [
    "**Solution**\n",
    "\n",
    "$P(E_b) = \\int_0^1 (1 - p)^3 \\cdot P(p|A=5, B=3)$\n",
    "$$P(p|A=5, B=3) = \\frac{P(A=5, B=3|p) \\cdot P(p)}{\\int_0^1 P(A=5, B=3|q) \\cdot P(q) dq}$$\n",
    "\n",
    "$P(p)$ and $P(q)$ are constant! -> Vors Integral ziehen und kürzen\n",
    "\n",
    "$\\frac{P(A=5, B=3|p)}{\\int_0^1 P(A=5, B=3|q)dq}$\n",
    "\n",
    "$P(A=5, B=3|p) = \\begin{pmatrix}8\\\\5\\end{pmatrix}p^5 (1 - p)^3 = \\frac{8!}{5!\\cdot3!} p^5 (1-p)^3 = 56 p^5 (1-p)^3$\n",
    "\n",
    "$P(E_B) = \\frac{\\int_0^1 (1-p)^3 \\cdot 56p^5 (1-p^3)dp}{\\int_0^1 56q^5 \\cdot (1-q)^3dq}$\n",
    "\n",
    "With beta function:\n",
    "\n",
    "$t = p\\\\\n",
    "x - 1 = 5\\\\\n",
    "y - 1 = 3$\n",
    "\n",
    "$\\frac{5! \\cdot 6!}{(6 + 7 - 1)!} \\cdot \\frac{(6 + 4 - 1)}{5!\\cdot3!} = \\frac{5! \\cdot 6!}{12!} \\cdot \\frac{9!}{5! \\cdot 3!} = \\frac{1}{11} \\approx 0.091$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "breakpoint": false
    }
   },
   "source": [
    "## Exercise 6-3: Optimal Separating Hyperplane\n",
    "\n",
    "Consider the following dataset consisting of points $\\begin{pmatrix}x_1\\\\x_2\\end{pmatrix}$ in $\\mathbb{R}^2$. Using a hyperplane, points marked by $×$ are to be mapped onto $\\leq 1$, points marked by $O$ are mapped onto $\\leq -1$.\n",
    "\n",
    "<img src=\"img/img-6_3.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "breakpoint": false
    }
   },
   "source": [
    "###(a)\n",
    "Find the support vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "breakpoint": false
    }
   },
   "source": [
    "**Solution**\n",
    "\n",
    "*For image, see solution for (b)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "breakpoint": false
    }
   },
   "source": [
    "###(b)\n",
    "Determine the equation of the optimal separating hyperplane $h = x^Tw$ and draw it within the figure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "breakpoint": false
    }
   },
   "source": [
    "**Solution**\n",
    "\n",
    "<img src=\"img/img-6_4.png\" width=400>\n",
    "\n",
    "$x_1 = 2\\\\\n",
    "h = x^Tw = x_0 \\cdot w_0 + x_1 \\cdot w_1 + x_2 \\cdot w_2\\\\\n",
    "x_1 \\cdot w_1 = -x_0w_0 - x_2w_2\\\\\n",
    "x_1 = -\\frac{x_0w_0}{w_1} - \\frac{x_2w_2}{w_1}\\\\\n",
    "x_1 = -\\frac{x_0w_0}{w_1}\\\\\n",
    "x_1 = 2\\\\\n",
    "2 = -\\frac{x_0w_0}{w_1}\\\\\n",
    "w_2 = 0\\\\\n",
    "w_1 = -x_0w_0$\n",
    "\n",
    "define: $w_1 = 1$\n",
    "\n",
    "$w_0 = -\\frac{w_1x_1}{x_0} = \\frac{-1 \\cdot 2}{1} = -2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "breakpoint": false
    }
   },
   "source": [
    "###(c)\n",
    "Compute the margin $C$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "breakpoint": false
    }
   },
   "source": [
    "**Solution**\n",
    "\n",
    "*See solution PDF on course website*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "breakpoint": false
    }
   },
   "source": [
    "## Exercise 6-4: Optimal Separating Hyperplane\n",
    "\n",
    "Determine the optimal separating hyperplane of the following dataset, partitioned into two classes $A$ and $B$:\n",
    "\n",
    "$$A = \\left\\{ p_1 = \\begin{pmatrix}2\\\\4\\end{pmatrix}, p_2 = \\begin{pmatrix}3\\\\-1\\end{pmatrix}, p_3 = \\begin{pmatrix}1\\\\0.5\\end{pmatrix}, p_4 = \\begin{pmatrix}2.5\\\\3\\end{pmatrix}, p_5 = \\begin{pmatrix}2\\\\4\\end{pmatrix} \\right\\}$$\n",
    "\n",
    "$$B = \\left\\{ p_6 = \\begin{pmatrix}0.5\\\\1.5\\end{pmatrix}, p_7 = \\begin{pmatrix}-1\\\\3\\end{pmatrix}, p_8 = \\begin{pmatrix}0\\\\0.5\\end{pmatrix} \\right\\}$$\n",
    "\n",
    "Instances of class $A$ shall be labeled with $1$, instances of class $B$ with $−1$.\n",
    "\n",
    "Visualize the result and name the support vectors. How wide is the margin?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "run_control": {
     "breakpoint": false
    }
   },
   "source": [
    "**Solution**\n",
    "\n",
    "*See solution PDF on course website*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
