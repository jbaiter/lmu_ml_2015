{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Sheet 7\n",
    "\n",
    "## Exercise 7-1: Multiple Choice\n",
    "\n",
    "Decide whether the following statements are true or false.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### exam: wrong answers for multiple choice questions deduct points;no answers no (negative) points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "breakpoint": false
    }
   },
   "source": [
    "### (a)\n",
    "\n",
    "When rolling a fair dice with numbers $\\in \\{1, ..., 6\\}^2$ the events “the first result is\n",
    "even” and “the second result is odd” are independent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "breakpoint": false
    }
   },
   "source": [
    "### (b)\n",
    "\n",
    "The expected value of a random variable is a non-linear function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "no\n",
    "\n",
    "Expected value:\n",
    "\n",
    "$E(X) = \\sum^\\infty _{i=1} p(x_i) \\cdot x_i$\n",
    "\n",
    "This is linear: exponent of $x$ is $1$, all $x_i$ are constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "breakpoint": false
    }
   },
   "source": [
    "### (c)\n",
    "\n",
    "The bias of an estimator is the squared difference between the true parameter and\n",
    "the expected value of the parameter estimate (averaged over many datasets)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "no\n",
    "\n",
    "this is the mean squared error(?), the bias is the deviation from the origin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "breakpoint": false
    }
   },
   "source": [
    "### (d)\n",
    "\n",
    "Regularization reduces the training error of a least squares model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "no\n",
    "\n",
    "Important: question asks for reduction in _training_ error\n",
    "\n",
    "Regularization aims to improve predictive performance by reducing overfitting on train data. As a result the training error will very likely increase and the test error should decrease."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "breakpoint": false
    }
   },
   "source": [
    "### (e)\n",
    "\n",
    "$k(x, y) = k_1 (x,y) \\cdot k_2 (x,y)$ is a legitimate kernel function for two legitimate\n",
    "kernel functions $k_1$, $k_2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yes\n",
    "\n",
    "(why?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "breakpoint": false
    }
   },
   "source": [
    "### (f)\n",
    "\n",
    "The product $tf_w \\cdot idf_w$ is always greater than $0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "no\n",
    "\n",
    "$tf_w$ could be 0, this is the case when the word does not appear in a document\n",
    "\n",
    "$idf_w$ (defined as $log(\\frac{N}{n_i})$) could also be 0, this happens when the word appears in every document: $N = n_i$ and thus $idf_w = log(1) = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "breakpoint": false
    }
   },
   "source": [
    "### (g)\n",
    "\n",
    "The marginal distribution of a random variable $X$ can be computed from a joint\n",
    "distribution of $X$ and another random variable $Y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yes\n",
    "\n",
    "see exercise sheet 5 ex 5-1 a)\n",
    "\n",
    "$P(X) = \\sum_Y P(X,Y)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "breakpoint": false
    }
   },
   "source": [
    "### (h)\n",
    "\n",
    "A neural network can be used to linearly separate classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "breakpoint": false
    }
   },
   "source": [
    "### (i)\n",
    "\n",
    "It is possible to compute the solution to a linear regression problem in closed\n",
    "form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yes\n",
    "\n",
    "closed form = one step (analytical solution may be a better term...?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "breakpoint": false
    }
   },
   "source": [
    "### (j)\n",
    "\n",
    "There exist homogeneous polynomial kernels with infinite-dimensional feature\n",
    "maps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "no (or maybe yes???)\n",
    "\n",
    "two-dimensional feature space\n",
    "$\\begin{pmatrix} x_1\\\\ x_2 \\end{pmatrix}$, $\\begin{pmatrix} y_1\\\\ y_2 \\end{pmatrix}$\n",
    "\n",
    "quadratik kernel: $<x,y>^2$:\n",
    "\n",
    "$x_1^2y_1^2 + 2x_1x_2y_1y_2 + x_2^2y_2^2$\n",
    "\n",
    "$\\begin{pmatrix} {x_1}^2 \\\\ \\sqrt{2x_1x_2} \\\\ {x_2}^2 \\end{pmatrix} $ $\\begin{pmatrix} {y_1}^2 \\\\ \\sqrt{2y_1y_2} \\\\ {y_2}^2 \\end{pmatrix} $\n",
    "\n",
    "but then again:\n",
    "\n",
    "this is possible for $k^n$, why shouldn't this be possible for $n+1$ and therefore for $\\infty$????\n",
    "\n",
    "So this might be mathematically possible (but not in programming languages???)\n",
    "\n",
    "\n",
    "(what does homogeneous mean???!!!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "breakpoint": false
    }
   },
   "source": [
    "## Exercise 7-2: The Perceptron\n",
    "\n",
    "Let $x \\in \\mathbb{R}^M$ be a data point. Let the output of the classification of a perceptron be defined as $sign (\\sum^M_{j=0} w_j x_j )$, where $x_0 = 1$ is constant.\n",
    "\n",
    "In the following figures, the black regions are to be mapped onto $\\hat{y} = 1$, the white regions are to be mapped\n",
    "onto $\\hat{y} = −1$. Which of the mappings are possible, considering the above defined perceptron of input dimension\n",
    "$M = 2$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Very well possible in exam!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "breakpoint": false
    }
   },
   "source": [
    "### (a)\n",
    "\n",
    "<img src=\"img/7-2-a.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from the picture we can get: $x_2 = 1$, $w_1 = 0$ \n",
    "\n",
    "Separating plane is $h_x = w_0 + w_1x_1 + w_2x_2$\n",
    "\n",
    "$\\Rightarrow w_2 = -\\frac{w_0}{w_2}$\n",
    "\n",
    "$w_1 = 1 \\Rightarrow w = \\vec{1, 0, -1}$\n",
    "\n",
    "$\\hat{y} = sign(h_x)$ yields correct results (for example $x = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$), no need to change sign."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "breakpoint": false
    }
   },
   "source": [
    "### (a)\n",
    "\n",
    "<img src=\"img/7-2-b.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "no possible hyperplane\n",
    "\n",
    "would need two hyperplanes or destinction of cases\n",
    "\n",
    "(dimension is set to $M=2$ in exercise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "breakpoint": false
    }
   },
   "source": [
    "### (a)\n",
    "\n",
    "<img src=\"img/7-2-c.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "possible!\n",
    "\n",
    "line equation: $x_2 = ax_1 + t = 2x_1 - 2$\n",
    "\n",
    "### TODO: warum ist der folgende Schritt möglich??\n",
    "$2x_1 - 2 = \\frac{w_1}{w_2}x_1 - \\frac{w_0}{w_2}$\n",
    "\n",
    "mit $w_0 = 1$:\n",
    "\n",
    "$\\frac{w_0}{w_2} = 2 \\Rightarrow w_2 = \\frac{1}{2}$\n",
    "\n",
    "und $-\\frac{w_1}{w_2} = 2 \\Rightarrow w_1 = -\\frac{1}{2} \\times 2 = -1$\n",
    "\n",
    "$w = \\begin{pmatrix} 1 \\\\ -1 \\\\ \\frac{1}{2} \\end{pmatrix}$\n",
    "\n",
    "Test yields correct results (for example $x = \\begin{pmatrix} 2 \\\\ 0 \\end{pmatrix}$), no need to change sign."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "breakpoint": false
    }
   },
   "source": [
    "## Exercise 7-3: Convolutional Neural Networks\n",
    "\n",
    "In this exercise we address a convolutional neural network (CNN) with one-dimensional input. While two-\n",
    "dimensional CNNs can be used for example for grayscale images, one-dimensional CNNs could be used for\n",
    "time-series such as temperature or humidity readings. Concepts for the 1D-case are equivalent to 2D networks.\n",
    "We interpret data in our network as three-dimensional arrays where a row denotes a feature map, a column\n",
    "denotes a single dimension of the observation, and the depth of the array represents different observations. As\n",
    "we will only work with a single input vector, the depth will always be one.\n",
    "\n",
    "Let the following CNN be given:\n",
    "\n",
    "- Input I: Matrix of size $1 \\times 12 \\times 1$. We therefore have an input with twelve dimensions consisting of a single feature map.\n",
    "- First convolutional layer with filters $F^1_0 = (−1,0,1)$ and $F^1_1 = (1,0, − 1)$ that generates two output feature maps from a single input feature map. Use valid mode for convolutions.\n",
    "- Max-pooling layer with stride 2 and filter size 2. Note that max-pooling pools each feature map separately.\n",
    "- Convolutional layer with convolutional kernel $F^2_0 = ((−1,0,1),(1,0, − 1))$ of size $2 \\times 3 \\times 1$.\n",
    "- Fully connected layer that maps all inputs to two outputs. The first output is calculated as the negative sum of all its inputs, and the second layer is calculated as the positive sum of all its inputs.\n",
    "- Sigmoidal activation function\n",
    "\n",
    "Calculate the response of the CNN for the two inputs (0,0,0,0,1,1,1,1,0,0,0,0) and (0,0,0,0,1,1,1,1,0,0,0,0).\n",
    "\n",
    "### second input should be (1,1,1,1,0,0,0,0,1,1,1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "breakpoint": false
    }
   },
   "source": [
    "- convolve 1: apply filter to create two input layers\n",
    "- max pool: group two inputs (filter size), take max, move two (stride), valid mode: stop at boundaries (values outside signal boundaries have no effect)\n",
    "(this is NOT grouping same numbers as the example may suggest (what i thought first...))\n",
    "- convolve 2: again applying filter\n",
    "- fully connected: negative sum of all feats | positive sum of all feats\n",
    "- sigmoid: $sigmoid(x) = \\frac{1}{1+e^{-x}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "solution not absolutely correct:\n",
    "\n",
    "output 1 = 0.9820 | 0.0180\n",
    "\n",
    "output 2 = 0.0180 | 0.9820\n",
    "\n",
    "($sigmoid(x) + sigmoid(-x) = 1$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "run_control": {
     "breakpoint": false
    }
   },
   "source": [
    "<img src=\"img/7-3.png\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
