{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano.tensor as T\n",
    "from theano import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "breakpoint": false
    }
   },
   "source": [
    "# Exercise 3-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "breakpoint": false
    }
   },
   "source": [
    "## (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "breakpoint": false
    }
   },
   "source": [
    "### i.\n",
    "\n",
    "Generate two scalar variables x1 and x2. These variables will later be filled with values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [],
   "source": [
    "x1 = T.scalar()\n",
    "x2 = T.scalar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "breakpoint": false
    }
   },
   "source": [
    "### ii.\n",
    "\n",
    "From the two variables construct an expression `e`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [],
   "source": [
    "e = x1**2 + x1*x2 + 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "breakpoint": false
    }
   },
   "source": [
    "Print the representation of this expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(((<TensorType(float64, scalar)> ** TensorConstant{2}) + (<TensorType(float64, scalar)> * <TensorType(float64, scalar)>)) + TensorConstant{3})\n"
     ]
    }
   ],
   "source": [
    "print(pp(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "breakpoint": false
    }
   },
   "source": [
    "### iii.\n",
    "\n",
    "As a next step, we want to evaluate this function. Generate a theano function `f` that allows us to do so, it should use the variables `x1` and `x2` as inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [],
   "source": [
    "f = function([x1, x2], e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "breakpoint": false
    }
   },
   "source": [
    "Execute the function for `x1=2` and `x2=3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.0\n"
     ]
    }
   ],
   "source": [
    "print(f(2, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "breakpoint": false
    }
   },
   "source": [
    "Print the function's representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<theano.compile.function_module.Function object at 0x7f66be452cf8>\n"
     ]
    }
   ],
   "source": [
    "print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "breakpoint": false
    }
   },
   "source": [
    "### iv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "breakpoint": false
    }
   },
   "source": [
    "Define two new variables `x3` and `x4`, and redefine `f` using `x3` and `x4` as inputs.\n",
    "*Hint*: Use the `givens` input parameter of `theano.function`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [],
   "source": [
    "x3 = T.scalar()\n",
    "x4 = T.scalar()\n",
    "f = function([x3, x4], e, givens={x1: x3, x2: x4})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "breakpoint": false
    }
   },
   "source": [
    "### v."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "breakpoint": false
    }
   },
   "source": [
    "Another interesting property of theano functions is that parameters can be updated when executing a function. To test this define a shared variable (`theano.shared`), set its initial value to zero, and redefine the previous expression by replacing `3` with this shared variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [],
   "source": [
    "state = shared(0)\n",
    "e = x1**2 + x1*x2 + state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "breakpoint": false
    }
   },
   "source": [
    "Generate a theano function from this expression that increases the output by `1` each time the function is called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [],
   "source": [
    "f = function([x1, x2], e, updates={state: state+1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "breakpoint": false
    }
   },
   "source": [
    "Call this function several times and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n",
      "11.0\n",
      "12.0\n",
      "13.0\n",
      "14.0\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    print(f(2, 3))\n",
    "print(state.get_value())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "run_control": {
     "breakpoint": false
    }
   },
   "source": [
    "While this example is nonesense, the concept of updates allows for easily updating the weights and biases of a neural network with this technique: The theano function is defined on the network loss and updates are conducted depending on the gradient of the current input batch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "breakpoint": false
    }
   },
   "source": [
    "### vi.\n",
    "\n",
    "As we have already mentioned, theano also allows differentiation. Write an expression that represents the gradient of `e` with respect to `x1`, i.e. the partial derivation of `e` with respect to `x1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [],
   "source": [
    "ge = grad(e, x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "breakpoint": false
    }
   },
   "source": [
    "Then generate a theano function that allows us to evaluate this expression. Evaluate it at x1=3, x2=1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.0\n"
     ]
    }
   ],
   "source": [
    "f = function([x1, x2], ge)\n",
    "print(f(3, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "breakpoint": false
    }
   },
   "source": [
    "Check the results by computing the gradient by hand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "breakpoint": false
    }
   },
   "source": [
    "*TODO*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "breakpoint": false
    }
   },
   "source": [
    "### vii.\n",
    "\n",
    "Theano can compute several partial derivatives at the same time. Generate an expression `g2` that computes the partial derivatives of `e` with respect to all free variables of `e`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [],
   "source": [
    "g2 = grad(e, [x1, x2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "breakpoint": false
    }
   },
   "source": [
    " How is g2 represented?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Elemwise{add,no_inplace}.0, Elemwise{mul}.0]\n"
     ]
    }
   ],
   "source": [
    "print(g2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "breakpoint": false
    }
   },
   "source": [
    "Test this expression by defining an appropriate theano function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(7.0), array(3.0)]\n"
     ]
    }
   ],
   "source": [
    "f = function([x1, x2], g2)\n",
    "print(f(3, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "breakpoint": false
    }
   },
   "source": [
    "## (d)\n",
    "\n",
    "**Broadcasting** is an extension of matrix operations simplifying life in machine learning, see [Theano Docs](http://deeplearning.net/software/theano/tutorial/numpy.html#broadcasting) and [SciPy Docs](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html).\n",
    "\n",
    "This technique is exessively used when working with artificial neural networks in the context of mini-batches. In the context of artificial neural networks broadcasting is used to apply a mathematical expression on a set of input vectors, i.e. a minibatch. We will test this using numpy for the sake of simplicity.\n",
    "\n",
    "Compute `A*B` and `B*A` with `A=[1,1],[2,2],[3,3],[4,4]]` and `B=[[2,3]]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A*B: [[ 2  3]\n",
      " [ 4  6]\n",
      " [ 6  9]\n",
      " [ 8 12]]\n",
      "B*A: [[ 2  3]\n",
      " [ 4  6]\n",
      " [ 6  9]\n",
      " [ 8 12]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.asarray([(1,1), (2,2), (3,3), (4,4)])\n",
    "B = np.asarray([(2, 3)])\n",
    "\n",
    "print(\"A*B: {}\".format(A*B))\n",
    "print(\"B*A: {}\".format(B*A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "breakpoint": false
    }
   },
   "source": [
    "Interpret the result.\n",
    "\n",
    "-> The smaller array is always temporarily re-shaped the fit the larger one, hence the two expressions are identical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "breakpoint": false
    }
   },
   "source": [
    "### (e)\n",
    "\n",
    "Compute `A.dot(B.T)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5]\n",
      " [10]\n",
      " [15]\n",
      " [20]]\n"
     ]
    }
   ],
   "source": [
    "print(A.dot(B.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "breakpoint": false
    }
   },
   "source": [
    "Interpret the results.\n",
    "\n",
    "-> *TODO*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "breakpoint": false
    }
   },
   "source": [
    "### (f)\n",
    "\n",
    "* Define a **Perceptron with 2 inputs and one output** using Theano.\n",
    "* Use the **data, labels and weights from exercise 1.4**.\n",
    "* Use the **sigmoid function from theano as an activation function** and set a **learning rate of exercise 3**.\n",
    "* As a **cost function** use the **squared Euclidean loss**: $\\sum\\limits_{i=0}^{N-1} (\\hat{y}_i - y_i)^2$\n",
    "* Generate an expression for calculating the gradient of this cost function.\n",
    "* Based on the gradient and the cost expressions, define a function receiving as input a matrix of feature vectors (a minibatch) and a label of vectors, calculating the cost of these inputs and updating the weights and biases of the neural network at the same time.\n",
    "* Finally, train the neural network.\n",
    "\n",
    "*Why the fuck are we suppossed to update/train a NEURAL NETWORK when the first sentence says that we are to define a PERCEPTRON?? =_=*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid((X \\dot W))\n",
      "sigmoid((X \\dot W))\n",
      "Sum{acc_dtype=float64}(((sigmoid((X \\dot W)) - Y) ** TensorConstant{2}))\n",
      "(X.T \\dot ((((fill(((sigmoid((X \\dot W)) - Y) ** TensorConstant{2}), fill(Sum{acc_dtype=float64}(((sigmoid((X \\dot W)) - Y) ** TensorConstant{2})), TensorConstant{1.0})) * TensorConstant{2}) * ((sigmoid((X \\dot W)) - Y) ** (TensorConstant{2} - TensorConstant{1}))) * sigmoid((X \\dot W))) * (TensorConstant{1.0} - sigmoid((X \\dot W)))))\n"
     ]
    }
   ],
   "source": [
    "# Data, labels and initial weights from exercise 1-4\n",
    "# Data with x_0 added to the front\n",
    "data = np.asarray([[2,4], [1, 0.5], [0.5, 1.5], [0, 0.5]], dtype='float64')\n",
    "# Add bias\n",
    "data = np.insert(data, 0, values=1, axis=1)\n",
    "# Replaced -1 with 0 to fit sigmoid activation function\n",
    "labels = np.asarray([1, 1, 0, 0], dtype='int8')\n",
    "initial_weights = np.asarray([0.0, 1.0, -1.0], dtype='float64')\n",
    "\n",
    "# Learning rate from exercise 1-3\n",
    "learning_rate = 0.2\n",
    "\n",
    "# Theano variables\n",
    "t_x = T.dmatrix('X')\n",
    "t_y = T.bvector('Y')\n",
    "t_W = shared(initial_weights, name=\"W\")\n",
    "\n",
    "# Theano expressions\n",
    "t_activation = T.nnet.sigmoid(T.dot(t_x, t_W))\n",
    "t_prediction = t_activation\n",
    "t_cost = T.sum((t_prediction - t_y)**2)\n",
    "t_grad_cost = grad(t_cost, t_W)\n",
    "\n",
    "print(pp(t_activation))\n",
    "print(pp(t_prediction))\n",
    "print(pp(t_cost))\n",
    "print(pp(t_grad_cost))\n",
    "\n",
    "train_func = theano.function([t_x, t_y], t_cost,\n",
    "                             updates=[(t_W, t_W - learning_rate*t_grad_cost)],\n",
    "                             allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at 0.004998064480008461 after 2361 iterations\n"
     ]
    }
   ],
   "source": [
    "from itertools import count\n",
    "t_W.set_value(initial_weights)\n",
    "for it in count():\n",
    "    cost = train_func(data, labels)\n",
    "    if cost <= 0.005:\n",
    "        print(\"Cost at {} after {} iterations\".format(cost, it))\n",
    "        break\n",
    "    elif it >= 5000:\n",
    "        print(\"Did not converge after 5000 iterations.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "run_control": {
     "breakpoint": false
    }
   },
   "source": [
    "Using the sigmoid function for activation, this is certain to never converge, since the output will never be exactly 0 or 1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
